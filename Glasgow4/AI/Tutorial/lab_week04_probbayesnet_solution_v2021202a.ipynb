{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence - COMPSCI4004 2025-2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Week 4: Probability and Bayesian Networks <small><small>v20212022a</small></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">MODEL SOLUTIONS</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aim**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab/tutorial the aim is to: \n",
    "* Get hands-on experience with discrete random variables, probabilities and distributions - in Python and on paper!\n",
    "* Formulate and implement a Bayesian network in Python\n",
    "* Apply basic inference methods in the network - in Python and on paper!\n",
    "\n",
    "**Guide**:\n",
    "\n",
    "The notebook has two main parts and two parts which are extra and can be carried out as self-study:\n",
    "\n",
    "   - Part I (Q4.0-Q4.3): Basic probability and inference (in Python and on paper). This is a warm-up exercise and should be completed relatively quickly. \n",
    "   - Part II (Q4.4): BayesNet I (the key question is Q4.4.4)\n",
    "   - Part III (Q4.5): BayesNet II [extra; this is open-ended an intended for self-study]  \n",
    "   - Part IV (Q4.6): A more flexible BayesNet toolbox. \n",
    "\n",
    "We also encourage you to work on the quiz during the Lab session.  \n",
    "   \n",
    "\n",
    "Each part contains specific tasks - often open-ended questions - that you'll need to carry out to make the notebook run or be able to understand the next steps. These are indicated with:\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> This is a task for you to carry out before proceeding. \n",
    "* <font color=green>CHECKPOINTS:</font> This indicates a key point you should understand before proceeding. If you're in doubt then ask then consult the lab assistants.\n",
    "* A basic model solution (marked with <font color=red>SOLUTION</font>) will be provided a week after the Lab session.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.0 Introduction & Housekeeping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will examine discrete random variables and discrete distributions (i.e., distributions which are easy to enumerate and relate to) and we will implement a Bayesian/belief network in Python.\n",
    "\n",
    "The exercise relies on the [AIMA toolbox](https://github.com/aimacode/aima-python), Python 3 (download it from Moodle not github!) - and is adapted from the `probability.ipynb` tutorial found in the AIMA toolbox. Note: the relevant files from the AIMA toolbox are provided in the lab 4 zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Prerequisites__\n",
    "\n",
    "Importing these modules from the provided AIMA module should run without error. If you get an error you probably need to update your Python installation.\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Remember to change the AIMA_TOOLBOX_ROOT variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "AIMA_TOOLBOX_ROOT=\"/Users/debasis/teaching/ai-2023/aima-python-uofg\"\n",
    "sys.path.append(AIMA_TOOLBOX_ROOT)\n",
    "\n",
    "from utils import (\n",
    "    product, argmax, element_wise_product, matrix_multiplication,\n",
    "    vector_to_diagonal, vector_add, scalar_vector_product, inverse_matrix,\n",
    "    weighted_sample_with_replacement, probability, isclose, normalize\n",
    ")\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# A specific helper function (no need to understand at this point!)\n",
    "def extend(s, var, val):\n",
    "    \"Copy the substitution s and extend it by setting var to val; return copy.\"\n",
    "    s2 = s.copy()\n",
    "    s2[var] = val\n",
    "    return s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.1 The basics - probability distributions in Python (\"warm-up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will examine a basic class for defining probability distributions over discrete random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.1.1 Variables and distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> What's is a discrete random variable?\n",
    "* <font color=dark-magenta>TASK:</font> What is a probability distribution?\n",
    "\n",
    "---\n",
    "\n",
    "#### Q4.1.2 Variables and distributions in Python\n",
    "* <font color=dark-magenta>TASK:</font> Skim though the `ProbDist` code below and make sure you understand how the distributions and events are specified. \n",
    "___Hint___: We use a class to make it easier to do inference later on but you could also implement a lot of this functionality using e.g.  of this in a basic numpy array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `ProbDist` defines a discrete probability distribution. We name our random variable and then assign probabilities to the different values of the random variable. Assigning probabilities to the values works similar to that of using a dictionary with keys being the Value and we assign to it the probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbDist:\n",
    "    \"\"\"A discrete probability distribution. You name the random variable\n",
    "    in the constructor, then assign and query probability of values.\n",
    "    >>> P = ProbDist('Flip'); P['H'], P['T'] = 0.25, 0.75; P['H']\n",
    "    0.25\n",
    "    >>> P = ProbDist('X', {'lo': 125, 'med': 375, 'hi': 500})\n",
    "    >>> P['lo'], P['med'], P['hi']\n",
    "    (0.125, 0.375, 0.5)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, varname='?', freqs=None):\n",
    "        \"\"\"If freqs is given, it is a dictionary of values - frequency pairs,\n",
    "        then ProbDist is normalized.\"\"\"\n",
    "        self.prob = {}\n",
    "        self.varname = varname\n",
    "        self.values = []\n",
    "        if freqs:\n",
    "            for (v, p) in freqs.items():\n",
    "                self[v] = p\n",
    "            self.normalize()\n",
    "\n",
    "    def __getitem__(self, val):\n",
    "        \"\"\"Given a value, return P(value).\"\"\"\n",
    "        try:\n",
    "            return self.prob[val]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "    def __setitem__(self, val, p):\n",
    "        \"\"\"Set P(val) = p.\"\"\"\n",
    "        if val not in self.values:\n",
    "            self.values.append(val)\n",
    "        self.prob[val] = p\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"Make sure the probabilities of all values sum to 1.\n",
    "        Returns the normalized distribution.\n",
    "        Raises a ZeroDivisionError if the sum of the values is 0.\"\"\"\n",
    "        total = sum(self.prob.values())\n",
    "        if not isclose(total, 1.0):\n",
    "            for val in self.prob:\n",
    "                self.prob[val] /= total\n",
    "        return self\n",
    "\n",
    "    def show_approx(self, numfmt='{:.3g}'):\n",
    "        \"\"\"Show the probabilities rounded and sorted by key, for the\n",
    "        sake of portable doctests.\"\"\"\n",
    "        return ', '.join([('{}: ' + numfmt).format(v, p)\n",
    "                          for (v, p) in sorted(self.prob.items())])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"P({})\".format(self.varname)\n",
    "    \n",
    "\n",
    "def event_values(event, variables):\n",
    "    u\"\"\"Return a tuple of the values of variables in event.\n",
    "    >>> event_values ({'A': 10, 'B': 9, 'C': 8}, ['C', 'A'])\n",
    "    (8, 10)\n",
    "    >>> event_values ((1, 2), ['C', 'A'])\n",
    "    (1, 2)\n",
    "    \"\"\"\n",
    "    if isinstance(event, tuple) and len(event) == len(variables):\n",
    "        return event\n",
    "    else:\n",
    "        return tuple([event[var] for var in variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Q4.1.3 Example: The unfair coin\n",
    "\n",
    "Consider an unfair coin which has 75% probability of coming out tail. Lets define the probability distribution for Flip, i.e. P(Flip).\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Step through/run the code below and make sure you appreciate how the ProbDist object can be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P(Flip)'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = ProbDist('Flip')\n",
    "p['H'], p['T'] = 0.25, 0.75\n",
    "p['T']\n",
    "\n",
    "repr(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter of the constructor **varname** has a default value of '?'. So if the name is not passed it defaults to ?. The keyword argument **freqs** can be a dictionary of values of random variable:probability. These are then normalized such that the probability values sum upto 1 using the **normalize** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = ProbDist(freqs={'low': 125, 'medium': 375, 'high': 500})\n",
    "p.varname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.125, 0.375, 0.5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p['low'], p['medium'], p['high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the **prob** and **varname** the object also separately keeps track of all the values of the distribution in a list called **values**. Every time a new value is assigned a probability it is appended to this list, This is done inside the **_ _setitem_ _** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['low', 'medium', 'high']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Q4.1.4 Example - Counting Animals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution by default is not normalized if values are added incremently. We can still force normalization by invoking the **normalize** method. This is relevant when we e.g. count events happing in the world. For example imagine counting the occurances of Mice, Dog and Cat on a farm and then wanting to quantify the probability of seeing each of these animals on the farm.\n",
    "\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Step through/run the code below and make sure you appreciate how the ProbDist object can be used in bith an unnormalized and normalized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 114, 64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = ProbDist('Y')\n",
    "p['Cat'] = 50\n",
    "p['Dog'] = 114\n",
    "p['Mice'] = 64\n",
    "(p['Cat'], p['Dog'], p['Mice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21929824561403508, 0.5, 0.2807017543859649)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.normalize()\n",
    "(p['Cat'], p['Dog'], p['Mice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to display the approximate values upto decimals using the **show_approx** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cat: 0.219, Dog: 0.5, Mice: 0.281'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.show_approx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.2 Joint Probability Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will define a basic Python class for a JOINT probability distributions over __discrete__ random variables, e.g. $P(X,Y)$ where X can be true or false. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.2.1 Basic joint distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Write down (on paper or in this notebook) the two possible variations of the product-rule for the joint distrbution  $P(X,Y)$ ?\n",
    "* <font color=dark-magenta>TASK:</font> Write down (on paper or in this notebook) the marginalization / sum-rule for $P(X,Y)$ (marginalizing over Y) ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>\n",
    "<font color=\"red\">SOLUTION</font>\n",
    "\n",
    "- $P(X,Y)=P(Y|X)P(X)=P(X|Y)P(Y)$\n",
    "- $P(X)=\\sum_y P(X,Y=y) =\\sum_y P(X|Y=y) P(Y=y)$\n",
    "\n",
    "<div style=\"border:2px solid red\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.2.2 Events\n",
    "\n",
    "The helper function **event_values** returns a tuple of the values of variables in event. An event is specified by a dict where the keys are the names of variables and the corresponding values are the value of the variable. Variables are specified with a list. The ordering of the returned tuple is same as those of the variables.\n",
    "\n",
    "\n",
    "Alternatively, if the event is specified by a list or tuple of equal length of the variables. Then the events tuple is returned as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event = {'A': 10, 'B': 9, 'C': 8}\n",
    "variables = ['C', 'A']\n",
    "event_values(event, variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Q4.2.3  Joint distribution class\n",
    "\n",
    "_A probability model is completely determined by the joint distribution for all of the random variables._ (**AIMA Section 13.3**) The function below implements the class **JointProbDist** which inherits from the **ProbDist** class. This class specifies a discrete probability distribute over a set of variables (e.g. X and Y). \n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Skim though the `JointProbDist` code below and make sure you understand how the distributions and events are specified. \n",
    "___Hint___: We use a class to make it easier to do inference later on but you could also implement a lot of this functionality using e.g.  of this in a basic numpy array. It is not critical that you undersatnd all aspects of the code but simply accept that it holds the $P(X,Y,...)$-values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointProbDist(ProbDist):\n",
    "    \"\"\"A discrete probability distribute over a set of variables.\n",
    "    >>> P = JointProbDist(['X', 'Y']); P[1, 1] = 0.25\n",
    "    >>> P[1, 1]\n",
    "    0.25\n",
    "    >>> P[dict(X=0, Y=1)] = 0.5\n",
    "    >>> P[dict(X=0, Y=1)]\n",
    "    0.5\"\"\"\n",
    "\n",
    "    def __init__(self, variables):\n",
    "        self.prob = {}\n",
    "        self.variables = variables\n",
    "        self.vals = defaultdict(list)\n",
    "\n",
    "    def __getitem__(self, values):\n",
    "        \"\"\"Given a tuple or dict of values, return P(values).\"\"\"\n",
    "        values = event_values(values, self.variables)\n",
    "        return ProbDist.__getitem__(self, values)\n",
    "\n",
    "    def __setitem__(self, values, p):\n",
    "        \"\"\"Set P(values) = p.  Values can be a tuple or a dict; it must\n",
    "        have a value for each of the variables in the joint. Also keep track\n",
    "        of the values we have seen so far for each variable.\"\"\"\n",
    "        values = event_values(values, self.variables)\n",
    "        self.prob[values] = p\n",
    "        for var, val in zip(self.variables, values):\n",
    "            if val not in self.vals[var]:\n",
    "                self.vals[var].append(val)\n",
    "\n",
    "    def values(self, var):\n",
    "        \"\"\"Return the set of possible values for a variable.\"\"\"\n",
    "        return self.vals[var]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"P({})\".format(self.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values for a Joint Distribution is a an ordered tuple in which each item corresponds to the value associate with a particular variable. For Joint Distribution of X, Y where X, Y take integer values this can be something like (18, 19)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.2.2 Example\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Step through/run the example code below and make sure you appreciate how the JointProbDist object can be used in defining a joint probability distrbution.\n",
    "\n",
    "To specify a Joint distribution we first need an ordered list of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P(['X', 'Y'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = ['X', 'Y']\n",
    "P_XY = JointProbDist(variables)\n",
    "P_XY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the **ProbDist** class **JointProbDist** also employes magic methods to assign probability to different values.\n",
    "The probability can be assigned in either of the two formats for all possible values of the distribution. The **event_values** call inside  **_ _getitem_ _**  and **_ _setitem_ _** does the required processing to make this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2, 0.5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_XY[1,1] = 0.2\n",
    "P_XY[dict(X=0, Y=1)] = 0.5\n",
    "\n",
    "(P_XY[1,1], P_XY[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to list all the values for a particular variable using the **values** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_XY.values('X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.2.2 Define a joint distrbution for the three variables X,Y,Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Define a joint distrbution for the three variables X,Y,Z using the `JointProbDist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>\n",
    "<font color=\"red\">SOLUTION</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P(['X', 'Y', 'Z'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = ['X', 'Y','Z']\n",
    "P_XYZ = JointProbDist(variables)\n",
    "P_XYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_XYZ[1,1,1] = 0.2\n",
    "P_XYZ[dict(X=0, Y=1, Z=0)] = 0.5\n",
    "P_XYZ\n",
    "\n",
    "(P_XYZ[1,1,0], P_XYZ[1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.3  Inference Using Full Joint Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we use the full Joint Distributions to calculate the posterior distribution given some evidence, i.e. an actual observation of the value of one or more variable (e.g. X=true). \n",
    "\n",
    "We represent evidence by using a python dictionary with variables as dict keys and dict values representing the values.\n",
    "\n",
    "This is illustrated in **AIMA Section 13.3** of the book. The functions **enumerate_joint** and **enumerate_joint_ask** implement this functionality. Under the hood they implement **Equation 13.9** from the AIMA book.\n",
    "\n",
    "$${P}(X | {e}) = \\alpha {P}(X, {e}) = \\alpha {P}({e}|X)P(X) = Î± \\sum_{y} {P}(X, {e}, {y})\\,\\,\\,\\,\\,\\, Eq.\\,(1)$$\n",
    "\n",
    "Here $\\alpha$ is the normalizing factor. $X$ is our query variable and $e$ is the evidence (i.e. one or more condition variables). According to the equation we enumerate on the remaining variables $y$ (not in evidence or query variable) i.e. all possible combinations of $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.3.1 Normalizing constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Determine an expression for $\\alpha$ in Eq (1) (hint use the product rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>\n",
    "<font color=\"red\">SOLUTION</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the product rule, i.e., $P(A,B)=P(A|B)P(B)$, we can directly identify $\\alpha$ as\n",
    "$$\\alpha = 1 / P(e)$$\n",
    "which can, in some cases, directly be evaluated as:\n",
    "\n",
    "$$P(e) = \\sum_{x,y} P(X=x,y, {e})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Q4.3.2 Dentist Example\n",
    "We will be using the same \"dentist\" example as the book and lecture, i.e., let us create the full joint distribution from **Figure 13.3**.\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Complete the specification below and validate (manually) that the formulation constitutes a proper joint distribution (how would you do that?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_joint = JointProbDist(['Cavity', 'Toothache', 'Catch'])\n",
    "full_joint[dict(Cavity=True, Toothache=True, Catch=True)]    = 0.108\n",
    "full_joint[dict(Cavity=True, Toothache=True, Catch=False)]   = 0.012\n",
    "full_joint[dict(Cavity=True, Toothache=False, Catch=True)]   = 0.072\n",
    "full_joint[dict(Cavity=True, Toothache=False, Catch=False)]  = 0.008\n",
    "# Insert your code (four lines missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>\n",
    "<font color=\"red\">SOLUTION</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_joint = JointProbDist(['Cavity', 'Toothache', 'Catch'])\n",
    "full_joint[dict(Cavity=True, Toothache=True, Catch=True)]    = 0.108\n",
    "full_joint[dict(Cavity=True, Toothache=True, Catch=False)]   = 0.012\n",
    "\n",
    "full_joint[dict(Cavity=True, Toothache=False, Catch=True)]   = 0.072\n",
    "full_joint[dict(Cavity=True, Toothache=False, Catch=False)]  = 0.008\n",
    "\n",
    "full_joint[dict(Cavity=False, Toothache=True, Catch=True)]   = 0.016\n",
    "full_joint[dict(Cavity=False, Toothache=True, Catch=False)]  = 0.064\n",
    "\n",
    "full_joint[dict(Cavity=False, Toothache=False, Catch=True)]  = 0.144\n",
    "full_joint[dict(Cavity=False, Toothache=False, Catch=False)] = 0.576\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Check: It sums to one !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.3.3 Computing marginal distrbutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Remind yourself of the the marginalisation rule/sum rule for joint distributions and outline how we can we manually find $P(cavity)$ from the joint distribution $P(Cavity, Toothache, Catch)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.3.4 Computing marginal distrbutions in our `JointProb` class \n",
    "\n",
    "Let us now look at the **enumerate_joint** function which returns the sum of those entries in $P$ consistent with $e$,provided variables is $P$'s remaining variables (the ones not in $e$). Here, $P$ refers to the full joint distribution. The function uses a recursive call in its implementation. The first parameter **variables** refers to remaining variables. The function in each recursive call keeps on variable constant while varying others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_joint(variables, e, P):\n",
    "    \"\"\"Return the sum of those entries in P consistent with e,\n",
    "    provided variables is P's remaining variables (the ones not in e).\"\"\"\n",
    "    if not variables:\n",
    "        return P[e]\n",
    "    Y, rest = variables[0], variables[1:]\n",
    "    return sum([enumerate_joint(rest, extend(e, Y, y), P)\n",
    "                for y in P.values(Y)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume we want to find **P(Toothache=True)**. This can be obtained by marginalization (**AIMA Equation 13.6**). We can use **enumerate_joint** to solve for this by taking Toothache=True as our evidence. **enumerate_joint** will return the sum of probabilities consistent with evidence i.e. the Marginal Probability (or distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Toothache=True)=0.2\n"
     ]
    }
   ],
   "source": [
    "evidence = dict(Toothache=True) \n",
    "variables = ['Cavity', 'Catch'] # variables not part of evidence\n",
    "P_toothache = enumerate_joint(variables, evidence, full_joint)\n",
    "print(\"P(Toothache=True)=\" +str(P_toothache))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we use the lower case notation `P_toothache` to indicate a true outcome of the Toothache random variable. We suggest using `P_nottoothache` to denote Toothache=False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Manually verify this results (hint: see the lecture notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.3.5 More complicated marginals\n",
    " We can use the same function to find more complex probabilities like **P(Cavity=True and Toothache=True)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Toothache=True,Cavity=True)=0.12\n"
     ]
    }
   ],
   "source": [
    "evidence = dict(Cavity=True, Toothache=True)\n",
    "variables = ['Catch'] # variables not part of evidence\n",
    "P_toothachecavity = enumerate_joint(variables, evidence, full_joint)\n",
    "print(\"P(Toothache=True,Cavity=True)=\" +str(P_toothachecavity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Manually verify this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Q4.3.6 Conditional marginals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to sum over probabilities satisfying given evidence allows us to compute conditional probabilities like $P(Cavity=True | Toothache=True)$ as we can rewrite this as \n",
    "\n",
    "$$P(Cavity=True\\, |\\, Toothache = True) = \\frac{P(Cavity=True \\, , \\, Toothache=True)}{P(Toothache=True)}\\, \\, \\, \\, Eq. (2)$$\n",
    "\n",
    "We have already calculated both the numerator and denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Cavity=True | Toothache=True )=0.6\n"
     ]
    }
   ],
   "source": [
    "P_cavity_toothache = P_toothachecavity/P_toothache\n",
    "print(\"P(Cavity=True | Toothache=True )=\" +str(P_cavity_toothache))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Manually verify this result using pen and paper (and perhaps a calculator)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.3.7 Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rewrite Eq (2) into the standard form of Bayes rule, i.e. $P(A|B)=P(B|A)P(A)/(B)$, (insert latex here or do it on paper). Hint: this is almost trivial if you know the product rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>\n",
    "<font color=\"red\">SOLUTION</font>\n",
    "\n",
    "$$P(Cavity=True\\, |\\, Toothache = True) = \\frac{P(Toothache=True \\, | \\, Cavity=True)  \\, P(Cavity=True)}{P(Toothache = True)}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"border:2px solid red\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.3.8 Implementing Bayes rule in Python via `enumerate_joint_ask`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the standard form of Bayes rule we are interested in the probability distribution of a particular variable conditioned on some evidence, e.g. $P(Toothache = True\\, |\\, Cavity=True)$. This can involve doing calculations like above for each possible value of the variable. This has been implemented slightly differently  using normalization in the function **enumerate_joint_ask** which returns a probability distribution over the values of the variable $X$, given the {var:val} observations **e**, in the **JointProbDist P**. The implementation of this function calls **enumerate_joint** for each value of the query variable and passes **extended evidence** with the new evidence having $X=x_i$. This is followed by normalization of the obtained distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_joint_ask(X, e, P):\n",
    "    \"\"\"Return a probability distribution over the values of the variable X,\n",
    "    given the {var:val} observations e, in the JointProbDist P. [Section 13.3]\n",
    "    >>> P = JointProbDist(['X', 'Y'])\n",
    "    >>> P[0,0] = 0.25; P[0,1] = 0.5; P[1,1] = P[2,1] = 0.125\n",
    "    >>> enumerate_joint_ask('X', dict(Y=1), P).show_approx()\n",
    "    '0: 0.667, 1: 0.167, 2: 0.167'\n",
    "    \"\"\"\n",
    "    assert X not in e, u\"Query variable must be distinct from evidence\"\n",
    "    Q = ProbDist(X)  # probability distribution for X, initially empty\n",
    "    Y = [v for v in P.variables if v != X and v not in e]  # hidden variables.\n",
    "    for xi in P.values(X):\n",
    "        Q[xi] = enumerate_joint(Y, extend(e, X, xi), P)\n",
    "    return Q.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us find $P(Cavity | Toothache=True)$ using **enumerate_joint_ask** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.39999999999999997)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_variable = 'Cavity'\n",
    "evidence = dict(Toothache=True)\n",
    "P_Cavity_Toothache = enumerate_joint_ask(query_variable, evidence, full_joint)\n",
    "(P_Cavity_Toothache[True], P_Cavity_Toothache[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> You can verify that the first value is the same as we obtained earlier by \"manual\" calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Q4.3.9 [optional] sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> For completeness - or a sanity check - compute (using Python) the value for $P(Cavity=True | Toothache=True)$ using the expression for Bayes rule derived in Q4.3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>\n",
    "<font color=\"red\">SOLUTION</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Toothache=True )=0.2\n"
     ]
    }
   ],
   "source": [
    "# Get denominator  - P(Toothache)\n",
    "evidence = dict(Toothache=True)\n",
    "variables = ['Cavity', 'Catch'] # variables not part of evidence\n",
    "P_toothache = enumerate_joint(variables, evidence, full_joint)\n",
    "print(\"P(Toothache=True )=\" +str(P_toothache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.39999999999999997)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get numerator I - P(Toothache | Cavity)\n",
    "query_variable = 'Toothache'\n",
    "evidence = dict(Cavity=True)\n",
    "P_Toothache_Cavity = enumerate_joint_ask(query_variable, evidence, full_joint)\n",
    "(P_Toothache_Cavity[True], P_Toothache_Cavity[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Cavity=True )=0.19999999999999998\n"
     ]
    }
   ],
   "source": [
    "# Get numerator  II - P(Cavity)\n",
    "evidence = dict(Cavity=True)\n",
    "variables = ['Toothache', 'Catch'] # variables not part of evidence\n",
    "P_cavity = enumerate_joint(variables, evidence, full_joint)\n",
    "print(\"P(Cavity=True )=\" + str(P_cavity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Cavity=True | Toothache=True)=0.5999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Use the std version of Bayes formula to compute the specific conditional\n",
    "P_cavity_toothache = (P_Toothache_Cavity[True] * P_cavity)/P_toothache\n",
    "print(\"P(Cavity=True | Toothache=True)=\" + str(P_cavity_toothache))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> The same as before; as expected!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A last sanity check.... check that the joint $P(Toothache=True,Cavity=True)$ is equal to the previosly computed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Cavity=True , Toothache=True)=0.11999999999999998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "P_toothachecavity = (P_Toothache_Cavity[True] * P_cavity)\n",
    "print(\"P(Cavity=True , Toothache=True)=\" + str(P_toothachecavity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.4  Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>__Warning:__ This part is more open-ended that Q4.0-Q4.3. While there are suggestions for tasks it up to you to explore the details of the code and applicaitons. </font>\n",
    "\n",
    "A Bayesian network is a representation of the joint probability distribution encoding a collection of conditional independence statements. This represent our __knowledge__ about these variables based on defined / observed probability distribution.\n",
    "\n",
    "A Bayes Network is implemented as the class **BayesNet**. It consisits of a collection of nodes implemented by the class **BayesNode**. The implementation in the above mentioned classes focuses only on boolean variables. Each node is associated with a variable and it contains a **conditional probabilty table (cpt)**. The **cpt** represents the probability distribution of the variable conditioned on its parents $P(X_i | parents(X_i))$.\n",
    "\n",
    "Let us dive into the **BayesNode** implementation (note it is NOT critical that you understand teh details!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BayesNode:\n",
    "    \"\"\"A conditional probability distribution for a boolean variable,\n",
    "    P(X | parents). Part of a BayesNet.\"\"\"\n",
    "\n",
    "    def __init__(self, X, parents, cpt):\n",
    "        \"\"\"X is a variable name, and parents a sequence of variable\n",
    "        names or a space-separated string.  cpt, the conditional\n",
    "        probability table, takes one of these forms:\n",
    "\n",
    "        * A number, the unconditional probability P(X=true). You can\n",
    "          use this form when there are no parents.\n",
    "\n",
    "        * A dict {v: p, ...}, the conditional probability distribution\n",
    "          P(X=true | parent=v) = p. When there's just one parent.\n",
    "\n",
    "        * A dict {(v1, v2, ...): p, ...}, the distribution P(X=true |\n",
    "          parent1=v1, parent2=v2, ...) = p. Each key must have as many\n",
    "          values as there are parents. You can use this form always;\n",
    "          the first two are just conveniences.\n",
    "\n",
    "        In all cases the probability of X being false is left implicit,\n",
    "        since it follows from P(X=true).\n",
    "\n",
    "        >>> X = BayesNode('X', '', 0.2)\n",
    "        >>> Y = BayesNode('Y', 'P', {T: 0.2, F: 0.7})\n",
    "        >>> Z = BayesNode('Z', 'P Q',\n",
    "        ...    {(T, T): 0.2, (T, F): 0.3, (F, T): 0.5, (F, F): 0.7})\n",
    "        \"\"\"\n",
    "        if isinstance(parents, str):\n",
    "            parents = parents.split()\n",
    "\n",
    "        # We store the table always in the third form above.\n",
    "        if isinstance(cpt, (float, int)):  # no parents, 0-tuple\n",
    "            cpt = {(): cpt}\n",
    "        elif isinstance(cpt, dict):\n",
    "            # one parent, 1-tuple\n",
    "            if cpt and isinstance(list(cpt.keys())[0], bool):\n",
    "                cpt = {(v,): p for v, p in cpt.items()}\n",
    "\n",
    "        assert isinstance(cpt, dict)\n",
    "        for vs, p in cpt.items():\n",
    "            assert isinstance(vs, tuple) and len(vs) == len(parents)\n",
    "            assert all(isinstance(v, bool) for v in vs)\n",
    "            assert 0 <= p <= 1\n",
    "\n",
    "        self.variable = X\n",
    "        self.parents = parents\n",
    "        self.cpt = cpt\n",
    "        self.children = []\n",
    "\n",
    "    def p(self, value, event):\n",
    "        \"\"\"Return the conditional probability\n",
    "        P(X=value | parents=parent_values), where parent_values\n",
    "        are the values of parents in event. (event must assign each\n",
    "        parent a value.)\n",
    "        >>> bn = BayesNode('X', 'Burglary', {T: 0.2, F: 0.625})\n",
    "        >>> bn.p(False, {'Burglary': False, 'Earthquake': True})\n",
    "        0.375\"\"\"\n",
    "        assert isinstance(value, bool)\n",
    "        ptrue = self.cpt[event_values(event, self.parents)]\n",
    "        return ptrue if value else 1 - ptrue\n",
    "\n",
    "    def sample(self, event):\n",
    "        \"\"\"Sample from the distribution for this variable conditioned\n",
    "        on event's values for parent_variables. That is, return True/False\n",
    "        at random according with the conditional probability given the\n",
    "        parents.\"\"\"\n",
    "        return probability(self.p(True, event))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr((self.variable, ' '.join(self.parents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor takes in the name of **variable**, **parents** and **cpt**. Here **variable** is a the name of the variable like 'Earthquake'. **parents** should a list or space separate string with variable names of parents. The conditional probability table is a dict {(v1, v2, ...): p, ...}, the distribution P(X=true | parent1=v1, parent2=v2, ...) = p. Here the keys are combination of boolean values that the parents take. The length and order of the values in keys should be same as the supplied **parent** list/string. In all cases the probability of X being false is left implicit, since it follows from P(X=true).\n",
    "\n",
    "In the example below we implement the network shown in **AIMA Figure 14.3** of the book :\n",
    "\n",
    "<img src=\"./resources/bayesnet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent knowlegde in this domain we define a function BayesNet which exploits the BayesNode in defining a full network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet:\n",
    "    \"\"\"Bayesian network containing only boolean-variable nodes.\"\"\"\n",
    "\n",
    "    def __init__(self, node_specs=[]):\n",
    "        \"\"\"Nodes must be ordered with parents before children.\"\"\"\n",
    "        self.nodes = []\n",
    "        self.variables = []\n",
    "        for node_spec in node_specs:\n",
    "            self.add(node_spec)\n",
    "\n",
    "    def add(self, node_spec):\n",
    "        \"\"\"Add a node to the net. Its parents must already be in the\n",
    "        net, and its variable must not.\"\"\"\n",
    "        node = BayesNode(*node_spec)\n",
    "        assert node.variable not in self.variables\n",
    "        assert all((parent in self.variables) for parent in node.parents)\n",
    "        self.nodes.append(node)\n",
    "        self.variables.append(node.variable)\n",
    "        for parent in node.parents:\n",
    "            self.variable_node(parent).children.append(node)\n",
    "\n",
    "    def variable_node(self, var):\n",
    "        \"\"\"Return the node for the variable named var.\n",
    "        >>> burglary.variable_node('Burglary').variable\n",
    "        'Burglary'\"\"\"\n",
    "        for n in self.nodes:\n",
    "            if n.variable == var:\n",
    "                return n\n",
    "        raise Exception(\"No such variable: {}\".format(var))\n",
    "\n",
    "    def variable_values(self, var):\n",
    "        \"\"\"Return the domain of var.\"\"\"\n",
    "        return [True, False]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'BayesNet({0!r})'.format(self.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### Q4.4.1 Define a BayeNet for the Burglary example\n",
    "\n",
    "We will now define the network for your problem:\n",
    "\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Complete the specification below (replace ? with their correct values from Fig 14.2 in the book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-8b2430293eed>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-8b2430293eed>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    {(T, T): 0.95, (T, F): ?, (F, T): 0.29, (F, F): ?}),\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "T, F = True, False\n",
    "\n",
    "burglary = BayesNet([\n",
    "    ('Burglary', '', 0.001),\n",
    "    ('Earthquake', '', 0.002),\n",
    "    ('Alarm', 'Burglary Earthquake',\n",
    "     {(T, T): 0.95, (T, F): ?, (F, T): 0.29, (F, F): ?}),\n",
    "    ('JohnCalls', 'Alarm', {T: ?, F: 0.05}),\n",
    "    ('MaryCalls', 'Alarm', {T: ?, F: ?})\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>\n",
    "<font color=\"red\">SOLUTION</font>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, F = True, False\n",
    "\n",
    "burglary = BayesNet([\n",
    "    ('Burglary', '', 0.001),\n",
    "    ('Earthquake', '', 0.002),\n",
    "    ('Alarm', 'Burglary Earthquake',\n",
    "     {(T, T): 0.95, (T, F): 0.94, (F, T): 0.29, (F, F): 0.001}),\n",
    "    ('JohnCalls', 'Alarm', {T: 0.90, F: 0.05}),\n",
    "    ('MaryCalls', 'Alarm', {T: 0.70, F: 0.01})\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border:2px solid red\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BayesNet** method **variable_node** allows to reach **BayesNode** instances inside a Bayes Net. It is possible to extract (and modify the cpt using this method e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(True, True): 0.95,\n",
       " (True, False): 0.94,\n",
       " (False, True): 0.29,\n",
       " (False, False): 0.001}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burglary.variable_node('Alarm').cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4.4.1 Compactness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bayes Network is typically a more compact representation of the full joint distribution and like full joint distributions allows us to do inference i.e. answer questions about probability distributions of random variables given some evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=dark-magenta>TASK:</font> Explain in your own words why a Bayes Network is **typically** a more compact representation that the full joint distrbution ? In what case is it not more compact ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>\n",
    "<font color=\"red\">SOLUTION</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "- Exploiting the conditional independence reduces the space needed to store the various probabilities, in practice typically to a approx. linear scaling in the number of variables.\n",
    "- In the \"worst\" case all variables are dependent and there are no savings in representing the joint as a BN compared to a full joint (other that providing a visual representation).\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"border:2px solid red\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4.4.2 Inference by Enumeration (tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply techniques similar to those used for **enumerate_joint_ask** and **enumerate_joint** to draw inference from Bayesian Networks. **enumeration_ask** and **enumerate_all** implement the algorithm described in **Figure 14.9** of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_all(variables, e, bn):\n",
    "    \"\"\"Return the sum of those entries in P(variables | e{others})\n",
    "    consistent with e, where P is the joint distribution represented\n",
    "    by bn, and e{others} means e restricted to bn's other variables\n",
    "    (the ones other than variables). Parents must precede children in variables.\"\"\"\n",
    "    if not variables:\n",
    "        return 1.0\n",
    "    Y, rest = variables[0], variables[1:]\n",
    "    Ynode = bn.variable_node(Y)\n",
    "    if Y in e:\n",
    "        return Ynode.p(e[Y], e) * enumerate_all(rest, e, bn)\n",
    "    else:\n",
    "        return sum(Ynode.p(y, e) * enumerate_all(rest, extend(e, Y, y), bn)\n",
    "                   for y in bn.variable_values(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**enumerate__all** recursively evaluates a general form of the **Equation 14.4** in the book.\n",
    "\n",
    "$${P}(X | {e}) = Î± {P}(X, {e}) = Î± \\sum_{y} {P}(X, {e}, {y})$$ \n",
    "\n",
    "such that $P(X, e, y)$ is written in the form of product of conditional probabilities **P(variable | parents(variable))** from the Bayesian Network.\n",
    "\n",
    "**enumeration_ask** calls **enumerate_all** on each value of query variable $X$ and finally normalizes them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumeration_ask(X, e, bn):\n",
    "    u\"\"\"Return the conditional probability distribution of variable X\n",
    "    given evidence e, from BayesNet bn. [Figure 14.9]\n",
    "    >>> enumeration_ask('Burglary', dict(JohnCalls=T, MaryCalls=T), burglary\n",
    "    ...  ).show_approx()\n",
    "    'False: 0.716, True: 0.284'\"\"\"\n",
    "    assert X not in e, u\"Query variable must be distinct from evidence\"\n",
    "    Q = ProbDist(X)\n",
    "    for xi in bn.variable_values(X):\n",
    "        Q[xi] = enumerate_all(bn.variables, extend(e, X, xi), bn)\n",
    "    return Q.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us solve the problem of finding out $P(Burglary=True | JohnCalls=True, MaryCalls=True)$ using the **burglary** network. **enumeration_ask** takes three arguments $X$ = variable name, $e$ = Evidence (in form a dict like previously explained), **bn** = The Bayes Net to do inference on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2841718353643929, 0.7158281646356071)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_B_JM = enumeration_ask('Burglary', {'JohnCalls': True, 'MaryCalls': True}, burglary)\n",
    "(P_B_JM[True],P_B_JM[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4.4.4 Manual inference in the Bayesian network\n",
    "* <font color=dark-magenta>TASK:</font> Manually (without Python) compute the distribution for $P(Burglary\\,,\\,MaryCalls\\,|\\,JohnCalls)$ ) (you don't need to insert the numerical expressions; only the relevant conditional distributions). Check with your lab assistant if you have got it right!\n",
    "\n",
    "Hint: you will often be asked to do something similar in the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>\n",
    "<font color=\"red\">SOLUTION</font>\n",
    "<br>\n",
    "\n",
    "We provide a general recipe for computing any conditional from any Bayes Net. <br>\n",
    "\n",
    "**Step 1)** Always write up the conditional exploiting all conditional independencies: <br>\n",
    "\n",
    "In this case: \n",
    "\n",
    "$$P(B,E,A,M,J) = P(E)P(B)P(A|E,B)P(M|A)P(J|A)$$\n",
    "\n",
    "\n",
    "**Step 2)** Figure out what expression you're looking for.<br>\n",
    "In this case we are looking for $P(B,M|J)$. \n",
    "\n",
    "Step 2.a) Which variables are involved and write the joint for that?<br>\n",
    "Here P(B,M,J).\n",
    "\n",
    "Step 2.b) Figure out how you can get to the expression (typ. a conditional) from the joint which can be done with Bayes rule or from the production rules.\n",
    "\n",
    "Here P(B,M,J)=P(B,M|J)P(J) which leads to \n",
    "\n",
    "$$P(B,M|J) = \\frac{P(B,M,J)}{P(J)}$$\n",
    "\n",
    "Note in some case it can be benificial to write $P(B,M|J)=\\frac{P(J|B,M)P(B,M)}{P()J}$ (but not nessesary).\n",
    "\n",
    "\n",
    "**Step 3)** Find the specific expression required to compute the expression found in Step 2 by marginalising out variables from the joint identified in Step 1.\n",
    "Here we need to find P(B,M,J) and P(J). \n",
    "\n",
    "$$\\displaylines{\n",
    "  P(B,M,J) &=& \\sum\\limits_{a \\in \\{ T,F\\} }^{} {\\sum\\limits_{e \\in \\{ T,F\\} }^{} {P(B,E = e,A = a,M,J)} }  \\cr \n",
    "   &=& \\sum\\limits_{a \\in \\{ T,F\\} }^{} {\\sum\\limits_{e \\in \\{ T,F\\} }^{} {\\left( {P(E = e)P(B)P(A = a|E = e,B)P(M|A = a)P(J|A = a)} \\right)} }  \\cr \n",
    "   &=& P(B)\\left( {\\sum\\limits_{a \\in \\{ T,F\\} }^{} {P(M|A = a)P(J|A = a)\\left( {\\sum\\limits_{e \\in \\{ T,F\\} }^{} {P(E = e)P(A = a|E = e,B)} } \\right)} } \\right) \\cr} $$\n",
    "\n",
    "<br>\n",
    "... and P(J) can be found by (or you can start from the full joint):\n",
    "\n",
    "$$\\displaylines{\n",
    "  P(J) &=& \\sum\\limits_{m \\in \\{ T,F\\} }^{} {\\sum\\limits_{b \\in \\{ T,F\\} }^{} {P(B = b,M = m,J)} }  \\cr \n",
    "   &=& ... \\cr} $$\n",
    "\n",
    "And we can insert these in the expresison found in the Step 2 (sometimes this leads to further opputunity for reductions , but not in general).\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Sometimes we are lucky and can easily identify the final result without using this mechnical approach; however, the outlined procedure gives you a fail safe approach (see also Ch 14 in the book).\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"border:2px solid red\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4.4.4 Inference in the Bayesian network (using Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to demonstrate very interesting properties of Bayesian Networks related to conditional independence and \"explaining away\", we will now compute a number of marginal and conditional distributions to highlight these properties. We are interested in investigating which variables influence each other and under which conditions!\n",
    "\n",
    "<img src=\"./resources/bayesnet.png\">\n",
    "\n",
    "We will be asking the following four questions:\n",
    "* Assume we have ***not*** observed whether the Alarm has gone off or not, will knowing $MaryCalls=true$ influence the probability of $JohnCalls$? (hint: consider the definition of conditional independence; variables are only independent when we have observed something about a parent!).)\n",
    "* Assume we have observed `Alarm=true`, will knowing $MaryCalls=true$ influence the probability of $JohnCalls$? (hint: consider the definition of conditional independence; variables are only independent when we have observed something about a parent!).\n",
    "* Assume we have ***not*** observed whether the Alarm has gone off or not, will knowing $Burglary=true$ influence the probability of $Earthquake$? (hint: investigate - using the book, internet etc- the concept of \"explaining away\").\n",
    "* Assume we have observed `Alarm=true`, will knowing $Burglary=true$ influence the probability of $JohnCalls$? (hint: investigate - using the book, internet etc- the concept of \"explaining away\").\n",
    "\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> Try to answer the above questions using your intuition before doing the numerical computations.\n",
    "\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> To investigate the concept of \"explaining away\", we suggest you compute the following distributions to explore the above questions:\n",
    "    * Compute $P(JohnCalls)$\n",
    "    * Compute $P(MaryCalls)$\n",
    "    * Compute $P(JohnCalls\\,|\\,MaryCalls=true)$\n",
    "    * Compute $P(MaryCalls\\,|\\,JohnCalls=true)$\n",
    "    * Compute $P(JohnCalls\\,|\\,Alarm=true)$\n",
    "    * Compute $P(MaryCalls\\,|\\,Alarm=true)$    \n",
    "    * Compute $P(JohnCalls\\,|\\,Alarm=true,MaryCalls=true)$\n",
    "    * Compute $P(MaryCalls\\,|\\,Alarm=true,JohnCalls=true)$\n",
    "\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font> To investigate the concept of conditional independence, we suggest you compute the following distributions to explore the above questions:   \n",
    "    * Compute $P(Burglary)$\n",
    "    * Compute $P(Earthquake)$      \n",
    "    * Compute $P(Burglary\\,|\\,Earthquake=true)$\n",
    "    * Compute $P(Earthquake\\,|\\,Burglary=true)$      \n",
    "    * Compute $P(Burglary\\,|\\,Alarm=true)$\n",
    "    * Compute $P(Earthquake\\,|\\,Alarm=true)$      \n",
    "    * Compute $P(Burglary\\,|\\,Alarm=true,Earthquake=true)$\n",
    "    * Compute $P(Earthquake\\,|\\,Alarm=true,Burglary=true)$ [hint: this value should be around 0.0033]   \n",
    "    \n",
    "    \n",
    "* <font color=dark-magenta>TASK:</font> Return to the four questions raised above and check that the numerical values  values aligns with your understanding. \n",
    "    \n",
    "    \n",
    "* <font color=green>CHECKPOINT</font>: Make sure you (as a group) discuss these aspects internally and with the tutor (or at least read through the solution when available!)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>\n",
    "<font color=\"red\">SOLUTION</font>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use a short-hand notation for the variable names, s.t. P_X_yz = P(X|Y=true,Z=true)\n",
      "--------------------------------------------------\n",
      "BOTTOM: Diverging connection, cond. independence\n",
      "--------------------------------------------------\n",
      "  \t  < True , False >\n",
      "P_J\t= <0.0521, 0.9479>\n",
      "P_M\t= <0.0117, 0.9883>\n",
      "P_J_m\t= <0.1776, 0.8224>\n",
      "P_M_j\t= <0.0400, 0.9600>\n",
      "P_J_a\t= <0.9000, 0.1000>\n",
      "P_M_a\t= <0.7000, 0.3000>\n",
      "P_J_ma\t= <0.9000, 0.1000>\n",
      "P_M_ja\t= <0.7000, 0.3000>\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "TOP: converging connections, explaining away\n",
      "--------------------------------------------------\n",
      " \t  < True , False >\n",
      "P_E\t= <0.0020, 0.9980>\n",
      "P_B\t= <0.0010, 0.9990>\n",
      "P_B_e\t= <0.0010, 0.9990>\n",
      "P_E_b\t= <0.0020, 0.9980>\n",
      "P_B_a\t= <0.3736, 0.6264>\n",
      "P_E_a\t= <0.2310, 0.7690>\n",
      "P_E_ba\t= <0.0020, 0.9980>\n",
      "P_B_ea\t= <0.0033, 0.9967>\n"
     ]
    }
   ],
   "source": [
    "print(\"We use a short-hand notation for the variable names, s.t. P_X_yz = P(X|Y=true,Z=true)\")\n",
    "\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"BOTTOM: Diverging connection, cond. independence\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"  \\t  < True , False >\")\n",
    "\n",
    "P_J = enumeration_ask('JohnCalls', {}, burglary)\n",
    "print(\"P_J\\t= <%.4f, %.4f>\" % (P_J[True],P_J[False]))\n",
    "\n",
    "P_M = enumeration_ask('MaryCalls', {}, burglary)\n",
    "print(\"P_M\\t= <%.4f, %.4f>\" % (P_M[True],P_M[False]))\n",
    "\n",
    "P_J_m = enumeration_ask('JohnCalls', {'MaryCalls': True}, burglary)\n",
    "print(\"P_J_m\\t= <%.4f, %.4f>\" % ( P_J_m[True],P_J_m[False]))\n",
    "\n",
    "P_M_j = enumeration_ask('MaryCalls', {'JohnCalls': True}, burglary)\n",
    "print(\"P_M_j\\t= <%.4f, %.4f>\" % ( P_M_j[True],P_M_j[False]))\n",
    "\n",
    "# with alarm\n",
    "P_J_a = enumeration_ask('JohnCalls', {'Alarm': True}, burglary)\n",
    "print(\"P_J_a\\t= <%.4f, %.4f>\" % ( P_J_a[True],P_J_a[False]))\n",
    "\n",
    "P_M_a = enumeration_ask('MaryCalls', {'Alarm': True}, burglary)\n",
    "print(\"P_M_a\\t= <%.4f, %.4f>\" % ( P_M_a[True],P_M_a[False]))\n",
    "\n",
    "# with alarmn and other caller\n",
    "P_J_ma = enumeration_ask('JohnCalls', {'Alarm': True,'MaryCalls': True}, burglary)\n",
    "print(\"P_J_ma\\t= <%.4f, %.4f>\" % ( P_J_ma[True],P_J_ma[False]))\n",
    "\n",
    "P_M_ja = enumeration_ask('MaryCalls', {'Alarm': True,'JohnCalls': True}, burglary)\n",
    "print(\"P_M_ja\\t= <%.4f, %.4f>\" % ( P_M_ja[True],P_M_ja[False]))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"TOP: converging connections, explaining away\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\" \\t  < True , False >\")\n",
    "P_E = enumeration_ask('Earthquake', {}, burglary)\n",
    "print(\"P_E\\t= <%.4f, %.4f>\" % ( P_E[True],P_E[False]))\n",
    "\n",
    "P_B= enumeration_ask('Burglary', {}, burglary)\n",
    "print(\"P_B\\t= <%.4f, %.4f>\" % ( P_B[True],P_B[False]))\n",
    "\n",
    "P_B_e = enumeration_ask('Burglary', {'Earthquake': True}, burglary)\n",
    "print(\"P_B_e\\t= <%.4f, %.4f>\" % (P_B_e[True], P_B_e[False]))\n",
    "\n",
    "P_E_b = enumeration_ask('Earthquake', {'Burglary': True}, burglary)\n",
    "print(\"P_E_b\\t= <%.4f, %.4f>\" % (P_E_b[True], P_E_b[False]))\n",
    "\n",
    "P_B_a = enumeration_ask('Burglary', {'Alarm': True}, burglary)\n",
    "print(\"P_B_a\\t= <%.4f, %.4f>\" % ( P_B_a[True],P_B_a[False]))\n",
    "\n",
    "P_E_a = enumeration_ask('Earthquake', {'Alarm': True}, burglary)\n",
    "print(\"P_E_a\\t= <%.4f, %.4f>\" % ( P_E_a[True],P_E_a[False]))\n",
    "\n",
    "\n",
    "P_E_ba= enumeration_ask('Earthquake', {'Alarm': True, 'Burglary': True}, burglary)\n",
    "print(\"P_E_ba\\t= <%.4f, %.4f>\" % (P_E_ba[True], P_E_ba[False]))\n",
    "\n",
    "P_B_ea= enumeration_ask('Burglary', {'Alarm': True, 'Earthquake': True}, burglary)\n",
    "print(\"P_B_ea\\t= <%.4f, %.4f>\" % (P_B_ea[True], P_B_ea[False]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conditional independence (the bottom diverging connection): When we do not know the specific value of Alarm the two values influence each other (i.e. both goes up compared to the base values i.e. $P(j) < P(j|m)$. When we know Alarm=true the two values naturally revert to the conditional probabilities. \n",
    "\n",
    "\n",
    "* \"Explaining away\" (the top converging connection): There are two reasons for the Alarm going off ($E$ and $B$). Without knowing if Alarm=true the two variables do not influence each other. When we know A=true both $P(E|A)$ and $P(B|A)$ goes up. However, when we observe one of the causal reason to be true the e.g. $B=true$ the other reason (here $P(E|B=true,A=true)$ ) reverts back to a low probability as we have already \"explained\" why the Alarm went off (albeit it doesn't revert to independent conditional, $P(E)$,  as the Alarm=true and there is still uncertainty as to the whether the there was also a Earthquake. They now influence each other through the Alarm node. The results is intuitive if you think about it...\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid red\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.5 BayesNet II [extra; self-study]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are asked to determine if adaptive (âcheatingâ) software is active in a specific car to circumvent environmental requirements. The software is suspected to change the operation of the engine conditioned on the environment (i.e., control or real environment). The knowledge for a particular manufacturer and model is shown in the BayesNet below and the variables\n",
    "are outlined in the following table:\n",
    "\n",
    "<img src=\"./resources/car2vars.png\" width=\"50%\">\n",
    "\n",
    "<img src=\"./resources/fn_bn_cars_r002b.png\" width=\"70%\">\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font>Manually determine an expression for the joint distribution $P(N,C,S,D,E)$ exploiting all the conditional independencies implied by the Bayesian network in the figure.\n",
    "\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font>Compute the how much memory we save by storing the conditionals compared to the full joint distribution?\n",
    "\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font>Manually determine an expression an numerical value for the probability of the software not being active given that we have observed the fuel consumption to be below the limit and the NOx level to be above the limit. The expression should allow numerical evaluation given the values.\n",
    "\n",
    "\n",
    "<div style=\"border:2px solid red\"></div>\n",
    "<font color=\"red\">SOLUTION</font>\n",
    "<br>\n",
    "See Quiz Week 4\n",
    "<div style=\"border:2px solid red\"></div>\n",
    "\n",
    "\n",
    "\n",
    "* <font color=dark-magenta>TASK:</font>Implement a BayesNet using the AIMA toolbox to automatically determine the numerical value.\n",
    "\n",
    "Forward you solution to the lecturer for validation (no solution will be provided upfront).\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.6 A more flexible library [extra;self-study]\n",
    "* <font color=dark-magenta>TASK:</font> The AIMA BayesNet toolbox is slightly limited in its functionality. It you are interested in building more advanced Bayesian Networks we recommend you try to recreate a simple BayesNet (e.g. the Earthquake example) in the `pomegranate` library (https://pomegranate.readthedocs.io/en/latest/install.html). Discuss your finding and experience with the tutors/lab assistants. What can you do in `pomegranate`that you can't do with the AIMA toolbox (hint: consider the type of variables to can model in AIMA and compare with `pomegranate`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
